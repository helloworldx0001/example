{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K    100% |████████████████████████████████| 317kB 368kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /Users/tony/.anaconda3/envs/py37/lib/python3.6/site-packages (from keras) (1.16.1)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl (51kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 17.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /Users/tony/.anaconda3/envs/py37/lib/python3.6/site-packages (from keras) (1.12.0)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 35kB/s ta 0:00:016\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /Users/tony/.anaconda3/envs/py37/lib/python3.6/site-packages (from keras) (1.2.0)\n",
      "Collecting pyyaml (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/a3/1d13970c3f36777c583f136c136f804d70f500168edc1edea6daa7200769/PyYAML-3.13.tar.gz (270kB)\n",
      "\u001b[K    100% |████████████████████████████████| 276kB 390kB/s ta 0:00:011\n",
      "\u001b[?25hCollecting h5py (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/21/1cdf7fa7868528b35c1a08a770eb9334279574a8b5f1d7a2966dcec14e42/h5py-2.9.0-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (6.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.3MB 3.8MB/s ta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
      "  Running setup.py bdist_wheel for pyyaml ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/tony/Library/Caches/pip/wheels/ad/da/0c/74eb680767247273e2cf2723482cb9c924fe70af57c334513f\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: h5py, keras-applications, keras-preprocessing, pyyaml, keras\n",
      "Successfully installed h5py-2.9.0 keras-2.2.4 keras-applications-1.0.7 keras-preprocessing-1.0.9 pyyaml-3.13\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-05fa6c69d5c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras as keras\n",
    "import math\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, Dense, Input, add, Activation, AveragePooling2D, GlobalAveragePooling2D, Lambda, concatenate\n",
    "from keras.initializers import he_normal\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras import optimizers, regularizers\n",
    "\n",
    "growth_rate        = 12 \n",
    "depth              = 100\n",
    "compression        = 0.5\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "img_channels       = 3\n",
    "num_classes        = 10\n",
    "batch_size         = 64         # 64 or 32 or other\n",
    "epochs             = 300\n",
    "iterations         = 782       \n",
    "weight_decay       = 1e-4\n",
    "\n",
    "mean = [125.307, 122.95, 113.865]\n",
    "std  = [62.9932, 62.0887, 66.7048]\n",
    "\n",
    "from keras import backend as K\n",
    "if('tensorflow' == K.backend()):\n",
    "    import tensorflow as tf\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch < 150:\n",
    "        return 0.1\n",
    "    if epoch < 225:\n",
    "        return 0.01\n",
    "    return 0.001\n",
    "\n",
    "def densenet(img_input,classes_num):\n",
    "    def conv(x, out_filters, k_size):\n",
    "        return Conv2D(filters=out_filters,\n",
    "                      kernel_size=k_size,\n",
    "                      strides=(1,1),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='he_normal',\n",
    "                      kernel_regularizer=regularizers.l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    def dense_layer(x):\n",
    "        return Dense(units=classes_num,\n",
    "                     activation='softmax',\n",
    "                     kernel_initializer='he_normal',\n",
    "                     kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "\n",
    "    def bn_relu(x):\n",
    "        x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    def bottleneck(x):\n",
    "        channels = growth_rate * 4\n",
    "        x = bn_relu(x)\n",
    "        x = conv(x, channels, (1,1))\n",
    "        x = bn_relu(x)\n",
    "        x = conv(x, growth_rate, (3,3))\n",
    "        return x\n",
    "\n",
    "    def single(x):\n",
    "        x = bn_relu(x)\n",
    "        x = conv(x, growth_rate, (3,3))\n",
    "        return x\n",
    "\n",
    "    def transition(x, inchannels):\n",
    "        outchannels = int(inchannels * compression)\n",
    "        x = bn_relu(x)\n",
    "        x = conv(x, outchannels, (1,1))\n",
    "        x = AveragePooling2D((2,2), strides=(2, 2))(x)\n",
    "        return x, outchannels\n",
    "\n",
    "    def dense_block(x,blocks,nchannels):\n",
    "        concat = x\n",
    "        for i in range(blocks):\n",
    "            x = bottleneck(concat)\n",
    "            concat = concatenate([x,concat], axis=-1)\n",
    "            nchannels += growth_rate\n",
    "        return concat, nchannels\n",
    "\n",
    "\n",
    "    nblocks = (depth - 4) // 6 \n",
    "    nchannels = growth_rate * 2\n",
    "\n",
    "\n",
    "    x = conv(img_input, nchannels, (3,3))\n",
    "    x, nchannels = dense_block(x,nblocks,nchannels)\n",
    "    x, nchannels = transition(x,nchannels)\n",
    "    x, nchannels = dense_block(x,nblocks,nchannels)\n",
    "    x, nchannels = transition(x,nchannels)\n",
    "    x, nchannels = dense_block(x,nblocks,nchannels)\n",
    "    x = bn_relu(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = dense_layer(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # load data\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test  = keras.utils.to_categorical(y_test, num_classes)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test  = x_test.astype('float32')\n",
    "    \n",
    "    # - mean / std\n",
    "    for i in range(3):\n",
    "        x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n",
    "        x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n",
    "\n",
    "    # build network\n",
    "    img_input = Input(shape=(img_rows,img_cols,img_channels))\n",
    "    output    = densenet(img_input,num_classes)\n",
    "    model     = Model(img_input, output)\n",
    "    \n",
    "    # model.load_weights('ckpt.h5')\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    # from keras.utils import plot_model\n",
    "    # plot_model(model, show_shapes=True, to_file='model.png')\n",
    "\n",
    "    # set optimizer\n",
    "    sgd = optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "    # set callback\n",
    "    tb_cb     = TensorBoard(log_dir='./densenet/', histogram_freq=0)\n",
    "    change_lr = LearningRateScheduler(scheduler)\n",
    "    ckpt      = ModelCheckpoint('./ckpt.h5', save_best_only=False, mode='auto', period=10)\n",
    "    cbks      = [change_lr,tb_cb,ckpt]\n",
    "\n",
    "    # set data augmentation\n",
    "    print('Using real-time data augmentation.')\n",
    "    datagen   = ImageDataGenerator(horizontal_flip=True,width_shift_range=0.125,height_shift_range=0.125,fill_mode='constant',cval=0.)\n",
    "\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # start training\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size), steps_per_epoch=iterations, epochs=epochs, callbacks=cbks,validation_data=(x_test, y_test))\n",
    "    model.save('densenet.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# senet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import math\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, Dense, Input, add, Activation, GlobalAveragePooling2D, multiply, Reshape\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras.initializers import he_normal\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "cardinality        = 4          # 4 or 8 or 16 or 32\n",
    "base_width         = 64\n",
    "inplanes           = 64\n",
    "expansion          = 4\n",
    "\n",
    "img_rows, img_cols = 32, 32     \n",
    "img_channels       = 3\n",
    "num_classes        = 10\n",
    "batch_size         = 64  # 120       \n",
    "iterations         = 781 # 416       # total data / iterations = batch size\n",
    "epochs             = 250\n",
    "weight_decay       = 0.0005\n",
    "\n",
    "mean = [125.307, 122.95, 113.865]\n",
    "std  = [62.9932, 62.0887, 66.7048]\n",
    "\n",
    "from keras import backend as K\n",
    "if('tensorflow' == K.backend()):\n",
    "    import tensorflow as tf\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    \n",
    "def scheduler(epoch):\n",
    "    if epoch < 150:\n",
    "        return 0.1\n",
    "    if epoch < 225:\n",
    "        return 0.01\n",
    "    return 0.001\n",
    "\n",
    "def resnext(img_input,classes_num):\n",
    "    global inplanes\n",
    "    def add_common_layer(x):\n",
    "        x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    def group_conv(x,planes,stride):\n",
    "        h = planes // cardinality\n",
    "        groups = []\n",
    "        for i in range(cardinality):\n",
    "            group = Lambda(lambda z: z[:,:,:, i * h : i * h + h])(x)\n",
    "            groups.append(Conv2D(h,kernel_size=(3,3),strides=stride,kernel_initializer=he_normal(),kernel_regularizer=regularizers.l2(weight_decay),padding='same',use_bias=False)(group))\n",
    "        x = concatenate(groups)\n",
    "        return x\n",
    "\n",
    "    def residual_block(x,planes,stride=(1,1)):\n",
    "\n",
    "        D = int(math.floor(planes * (base_width/64.0)))\n",
    "        C = cardinality\n",
    "\n",
    "        shortcut = x\n",
    "        \n",
    "        y = Conv2D(D*C,kernel_size=(1,1),strides=(1,1),padding='same',kernel_initializer=he_normal(),kernel_regularizer=regularizers.l2(weight_decay),use_bias=False)(shortcut)\n",
    "        y = add_common_layer(y)\n",
    "\n",
    "        y = group_conv(y,D*C,stride)\n",
    "        y = add_common_layer(y)\n",
    "\n",
    "        y = Conv2D(planes*expansion, kernel_size=(1,1), strides=(1,1), padding='same', kernel_initializer=he_normal(),kernel_regularizer=regularizers.l2(weight_decay),use_bias=False)(y)\n",
    "        y = add_common_layer(y)\n",
    "\n",
    "        if stride != (1,1) or inplanes != planes * expansion:\n",
    "            shortcut = Conv2D(planes * expansion, kernel_size=(1,1), strides=stride, padding='same', kernel_initializer=he_normal(),kernel_regularizer=regularizers.l2(weight_decay),use_bias=False)(x)\n",
    "            shortcut = BatchNormalization(momentum=0.9, epsilon=1e-5)(shortcut)\n",
    "\n",
    "        y = squeeze_excite_block(y)\n",
    "\n",
    "        y = add([y,shortcut])\n",
    "        y = Activation('relu')(y)\n",
    "        return y\n",
    "    \n",
    "    def residual_layer(x, blocks, planes, stride=(1,1)):\n",
    "        x = residual_block(x, planes, stride)\n",
    "        inplanes = planes * expansion\n",
    "        for i in range(1,blocks):\n",
    "            x = residual_block(x,planes)\n",
    "        return x\n",
    "\n",
    "    def squeeze_excite_block(input, ratio=16):\n",
    "        init = input\n",
    "        channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1  # compute channel axis\n",
    "        filters = init._keras_shape[channel_axis]  # infer input number of filters\n",
    "        se_shape = (1, 1, filters) if K.image_data_format() == 'channels_last' else (filters, 1, 1)  # determine Dense matrix shape\n",
    "\n",
    "        se = GlobalAveragePooling2D()(init)\n",
    "        se = Reshape(se_shape)(se)\n",
    "        se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay), use_bias=False)(se)\n",
    "        se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay), use_bias=False)(se)\n",
    "        x = multiply([init, se])\n",
    "        return x\n",
    "\n",
    "    def conv3x3(x,filters):\n",
    "        x = Conv2D(filters=filters, kernel_size=(3,3), strides=(1,1), padding='same',kernel_initializer=he_normal(),kernel_regularizer=regularizers.l2(weight_decay),use_bias=False)(x)\n",
    "        return add_common_layer(x)\n",
    "\n",
    "    def dense_layer(x):\n",
    "        return Dense(classes_num,activation='softmax',kernel_initializer=he_normal(),kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "\n",
    "\n",
    "    # build the resnext model    \n",
    "    x = conv3x3(img_input,64)\n",
    "    x = residual_layer(x, 3, 64)\n",
    "    x = residual_layer(x, 3, 128,stride=(2,2))\n",
    "    x = residual_layer(x, 3, 256,stride=(2,2))\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = dense_layer(x)\n",
    "    return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # load data\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test  = keras.utils.to_categorical(y_test, num_classes)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test  = x_test.astype('float32')\n",
    "    \n",
    "    # - mean / std\n",
    "    for i in range(3):\n",
    "        x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n",
    "        x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n",
    "\n",
    "    # build network\n",
    "    img_input = Input(shape=(img_rows,img_cols,img_channels))\n",
    "    output    = resnext(img_input,num_classes)\n",
    "    senet    = Model(img_input, output)\n",
    "    print(senet.summary())\n",
    "\n",
    "    # load weight\n",
    "    # senet.load_weights('senet.h5')\n",
    "\n",
    "    # set optimizer\n",
    "    sgd = optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n",
    "    senet.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "    # set callback\n",
    "    tb_cb     = TensorBoard(log_dir='./senet/', histogram_freq=0)                                   # tensorboard log\n",
    "    change_lr = LearningRateScheduler(scheduler)                                                    # learning rate scheduler\n",
    "    ckpt      = ModelCheckpoint('./ckpt_senet.h5', save_best_only=False, mode='auto', period=10)    # checkpoint \n",
    "    cbks      = [change_lr,tb_cb,ckpt]                   \n",
    "\n",
    "    # set data augmentation\n",
    "    print('Using real-time data augmentation.')\n",
    "    datagen   = ImageDataGenerator(horizontal_flip=True,width_shift_range=0.125,height_shift_range=0.125,fill_mode='constant',cval=0.)\n",
    "\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # start training\n",
    "    senet.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size), steps_per_epoch=iterations, epochs=epochs, callbacks=cbks,validation_data=(x_test, y_test))\n",
    "    senet.save('senet.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
